[
    {
        "title": "Study Backs Google’s Claims: AI Search Boosts User Satisfaction",
        "url": "https://www.searchenginejournal.com/study-backs-googles-claims-ai-search-boosts-user-satisfaction/523059/",
        "content": "A new study finds that despite concerns about AI in online services, users are more satisfied with search engines and social media platforms than before.\n\nThe American Customer Satisfaction Index (ACSI) conducted its annual survey of search and social media users, finding that satisfaction has either held steady or improved.\n\nThis comes at a time when major tech companies are heavily investing in AI to enhance their services.\n\nSearch Engine Satisfaction Holds Strong\n\nGoogle, Bing, and other search engines have rapidly integrated AI features into their platforms over the past year. While critics have raised concerns about potential negative impacts, the ACSI study suggests users are responding positively.\n\nGoogle maintains its position as the most satisfying search engine with an ACSI score of 81, up 1% from last year. Users particularly appreciate its AI-powered features.\n\nInterestingly, Bing and Yahoo! have seen notable improvements in user satisfaction, notching 3% gains to reach scores of 77 and 76, respectively. These are their highest ACSI scores in over a decade, likely due to their AI enhancements launched in 2023.\n\nThe study hints at the potential of new AI-enabled search functionality to drive further improvements in the customer experience. Bing has seen its market share improve by small but notable margins, rising from 6.35% in the first quarter of 2023 to 7.87% in Q1 2024.\n\nCustomer Experience Improvements\n\nThe ACSI study shows improvements across nearly all benchmarks of the customer experience for search engines. Notable areas of improvement include:\n\nEase of navigation\n\nEase of using the site on different devices\n\nLoading speed performance and reliability\n\nVariety of services and information\n\nFreshness of content\n\nThese improvements suggest that AI enhancements positively impact various aspects of the search experience.\n\nSocial Media Sees Modest Gains\n\nFor the third year in a row, user satisfaction with social media platforms is on the rise, increasing 1% to an ACSI score of 74.\n\nTikTok has emerged as the new industry leader among major sites, edging past YouTube with a score of 78. This underscores the platform’s effective use of AI-driven content recommendations.\n\nMeta’s Facebook and Instagram have also seen significant improvements in user satisfaction, showing 3-point gains. While Facebook remains near the bottom of the industry at 69, Instagram’s score of 76 puts it within striking distance of the leaders.\n\nChallenges Remain\n\nDespite improvements, the study highlights ongoing privacy and advertising challenges for search engines and social media platforms. Privacy ratings for search engines remain relatively low but steady at 79, while social media platforms score even lower at 73.\n\nAdvertising experiences emerge as a key differentiator between higher- and lower-satisfaction brands, particularly in social media. New ACSI benchmarks reveal user concerns about advertising content’s trustworthiness and personal relevance.\n\nWhy This Matters For SEO Professionals\n\nThis study provides an independent perspective on how users are responding to the AI push in online services. For SEO professionals, these findings suggest that:\n\nAI-enhanced search features resonate with users, potentially changing search behavior and expectations. The improving satisfaction with alternative search engines like Bing may lead to a more diverse search landscape. The continued importance of factors like content freshness and site performance in user satisfaction aligns with long-standing SEO best practices.\n\nAs AI becomes more integrated into our online experiences, SEO strategies may need to adapt to changing user preferences.\n\nFeatured Image: kate3155/Shutterstock"
    },
    {
        "title": "What Can AI Do For Healthcare Marketing In 2024?",
        "url": "https://www.searchenginejournal.com/callrail-ai-healthcare-marketing-2024-spa/522817/",
        "content": "This post was sponsored by CallRail. The opinions expressed in this article are the sponsor’s own.\n\nArtificial intelligence (AI) has huge potential for healthcare practices. It can assist with diagnosis and treatment, as well as administrative and marketing tasks. Yet, many practices are still wary of using AI, especially regarding marketing.\n\nThe reality is that AI is here to stay, and many healthcare practices are beginning to use the technology. According to one recent study, 89% of healthcare professionals surveyed said that they were at least evaluating AI products, experimenting with them, or had implemented AI.\n\nTo help you determine whether using AI is right for your healthcare practice, let’s take a look at some of the pros and cons of using AI while marketing.\n\nThe Pros And Cons Of AI For Healthcare Practices\n\nHealthcare practices that choose to implement AI in safe and appropriate ways to help them with their marketing and patient experience efforts can reap many benefits, including more leads, conversions, and satisfied patients. In fact, 41% of healthcare organizations say their marketing team already uses AI.\n\nPatients also expect healthcare practices to begin to implement AI in a number of ways. In one dentistry study, patients overall showed a positive attitude toward using AI. So, what’s holding your practice back from adding new tools and finding new use cases for AI? Let’s take a look at common concerns.\n\nCon #1: Data Security And Privacy Concerns\n\nLet’s get one of the biggest concerns with AI and healthcare out of the way first. Healthcare practices must follow all privacy and security regulations related to patients’ protected health information (PHI) to maintain HIPAA compliance.\n\nSo, concerns over whether AI can be used in a way that doesn’t interfere with HIPAA compliance are valid. In addition, there are also concerns about the open-source nature of popular GenAI models, which means sensitive practice data might be exposed to competitors or even hackers.\n\nPro #1: AI Can Help You Get More Value From Your Data Securely\n\nWhile there are valid concerns about how AI algorithms make decisions and data privacy concerns, AI can also be used to enrich data to help you achieve your marketing goals while still keeping it protected.\n\nWith appropriate guardrails and omission procedures in place, you can apply AI to gain insights from data that matters to you without putting sensitive data at risk.\n\nFor example, our CallRail Labs team is helping marketers remove their blind spots by using AI to analyze and detect critical context clues that help you qualify which calls are your best leads so you can follow up promptly.\n\nAt the same time, we know how important it is for healthcare companies to keep PHI secure, which is why we integrate with healthcare privacy platforms like Freshpaint. It can help you bridge the gap between patient privacy and digital marketing.\n\nIn addition, our AI-powered Healthcare Plan automatically redacts sensitive patient-protected health information from call transcripts, enforces obligatory log-outs to prevent PHI from becoming public, provides full audit trail logging, and even features unique logins and credentials for every user, which helps eliminate the potential for PHI to be accidentally exposed to employees who don’t need access to that information.\n\nCon #2: AI Is Impersonal\n\nHaving a good patient experience is important to almost all patients, and according to one survey, 52% of patients said a key part of a good patient experience is being treated with respect. Almost as many (46%) said they want to be addressed as a person. Given these concerns, handing over content creation or customer interactions to AI can feel daunting. While an AI-powered chatbot might be more efficient than a human in a call center, you also don’t want patients to feel like you’ve delegated customer service to a robot. Trust is the key to building patient relationships.\n\nPro #2: AI Can Improve The Patient Experience\n\nWorries over AI making patient interactions feel impersonal are reasonable, but just like any other type of tool, it’s how you use AI that matters. There are ways to deploy AI that can actually enhance the patient experience and, by doing so, give your healthcare practice an advantage over your competitors.\n\nThe answer isn’t in offloading customer interaction to chatbots. But AI can help you analyze customer interactions to make customer service more efficient and helpful.\n\nWith CallRail’s AI-powered Premium Conversation Intelligence™, which transcribes, summarizes, and analyzes each call, you can quickly assess your patients’ needs and concerns and respond appropriately with a human touch. For instance, Premium Conversation Intelligence can identify and extract common keywords and topics from call transcripts. This data reveals recurring themes, such as frequently asked questions, common complaints, and popular services. A healthcare practice could then use these insights to tailor their marketing campaigns to address the most pressing patient concerns.\n\nCon #3: AI Seems Too Complicated To Use\n\nLet’s face it: new technology is risky, and for healthcare practices especially, risk is scary. With AI, some of the risk comes from its perceived complexity. Identifying the right use cases for your practice, selecting the right tools, training your staff, and changing workflows can all feel quite daunting. Figuring this out takes time and money. And, if there aren’t clear use cases and ROI attached, the long-term benefits may not be worth the short-term impact on business.\n\nPro #3: AI Can Save Time And Money\n\nUsing a computer or a spreadsheet for the first time probably also felt complicated – and on the front end, took some time to learn. However, you know that using these tools, compared to pen, paper, and calculators, has saved an enormous amount of time, making the upfront investment clearly worth it. Compared to many technologies, AI tools are often intuitive and only require you to learn a few simple things like writing prompts, refining prompts, reviewing reports, etc. Even if it takes some time to learn new AI tools, the time savings will be worth it once you do.\n\nTo get the greatest return on investment, focus on AI solutions that take care of time-intensive tasks to free up time for innovation. With the right use cases and tools, AI can help solve complexity without adding complexity. For example, with Premium Conversation Intelligence, our customers spend 60% less time analyzing calls each week, and they’re using that time to train staff better, increase their productivity, and improve the patient experience.\n\nCon #4: AI Marketing Can Hurt Your Brand\n\nMany healthcare practices are excited to use GenAI tools to accelerate creative marketing efforts, like social media image creation and article writing. But consumers are less excited. In fact, consumers are more likely to say that the use of AI makes them distrusting (40%), rather than trusting (19%), of a brand. In a market where trust is the most important factor for patients when choosing healthcare providers, there is caution and hesitancy around using GenAI for marketing.\n\nPro #4: AI Helps Make Your Marketing Better\n\nWhile off-brand AI images shared on social media can be bad brand marketing, there are many ways AI can elevate your marketing efforts without impacting the brand perception. From uncovering insights to improving your marketing campaigns and maximizing the value of each marketing dollar spent to increasing lead conversion rates and decreasing patient churn, AI can help you tackle these problems faster and better than ever.\n\nAt CallRail, we’re using AI to tackle complex challenges like multi-conversation insights. CallRail can give marketers instant access to a 3-6 sentence summary for each call, average call sentiment, notable trends behind positive and negative interactions, and a summary of commonly asked questions. Such analysis would take hours and hours for your marketing team to do manually, but with AI, you have call insights at your fingertips to help drive messaging and keyword decisions that can improve your marketing attribution and the patient experience.\n\nCon #5: Adapting AI Tools Might Cause Disruption\n\nAs a modern healthcare practice, your tech stack is the engine that runs your business. When onboarding any new technology, there are always concerns about how well it will integrate with existing technology and tools you use and whether it supports HIPAA compliance. There may also be concern about how AI tools can fit into your existing workflows without causing disruption.\n\nPro #5: AI Helps People Do Their Jobs Better\n\nPairing the right AI tool for roles with repetitive tasks can be a win for your staff and your practice. For example, keeping up with healthcare trends is important for marketers to improve messaging and campaigns.\n\nAn AI-powered tool that analyzes conversations and provides call highlights can help healthcare marketers identify keyword and Google Ad opportunities so they can focus on implementing the most successful marketing strategy rather than listening to hours of call recordings. In addition, CallRail’s new AI-powered Convert Assist helps healthcare marketers provide a better patient experience. With AI-generated call coaching, marketers can identify what went well and what to improve after every conversation.\n\nWhat’s more, with a solution like CallRail, which offers a Healthcare Plan and will sign a business associate agreement (BAA), you are assured that we will comply with HIPAA controls within our service offerings to ensure that your call tracking doesn’t expose you to potential fines or litigation. Moreover, we also integrate with other marketing tools, like Google Ads, GA4, and more, making it easy to integrate our solution into your existing technologies and workflows.\n\nLet CallRail Show You The Pros Of AI\n\nIf you’re still worried about using AI in your healthcare practice, start with a trusted solution like CallRail that has proven ROI for AI-powered tools and a commitment to responsible AI development. You can talk to CallRail’s experts or test the product out for yourself with a 14-day free trial.\n\nImage Credits\n\nFeatured Image: Image by CallRail. Used with permission."
    },
    {
        "title": "Study Backs Google’s Claims: AI Search Boosts User Satisfaction",
        "url": "https://www.searchenginejournal.com/study-backs-googles-claims-ai-search-boosts-user-satisfaction/523059/",
        "content": "A new study finds that despite concerns about AI in online services, users are more satisfied with search engines and social media platforms than before.\n\nThe American Customer Satisfaction Index (ACSI) conducted its annual survey of search and social media users, finding that satisfaction has either held steady or improved.\n\nThis comes at a time when major tech companies are heavily investing in AI to enhance their services.\n\nSearch Engine Satisfaction Holds Strong\n\nGoogle, Bing, and other search engines have rapidly integrated AI features into their platforms over the past year. While critics have raised concerns about potential negative impacts, the ACSI study suggests users are responding positively.\n\nGoogle maintains its position as the most satisfying search engine with an ACSI score of 81, up 1% from last year. Users particularly appreciate its AI-powered features.\n\nInterestingly, Bing and Yahoo! have seen notable improvements in user satisfaction, notching 3% gains to reach scores of 77 and 76, respectively. These are their highest ACSI scores in over a decade, likely due to their AI enhancements launched in 2023.\n\nThe study hints at the potential of new AI-enabled search functionality to drive further improvements in the customer experience. Bing has seen its market share improve by small but notable margins, rising from 6.35% in the first quarter of 2023 to 7.87% in Q1 2024.\n\nCustomer Experience Improvements\n\nThe ACSI study shows improvements across nearly all benchmarks of the customer experience for search engines. Notable areas of improvement include:\n\nEase of navigation\n\nEase of using the site on different devices\n\nLoading speed performance and reliability\n\nVariety of services and information\n\nFreshness of content\n\nThese improvements suggest that AI enhancements positively impact various aspects of the search experience.\n\nSocial Media Sees Modest Gains\n\nFor the third year in a row, user satisfaction with social media platforms is on the rise, increasing 1% to an ACSI score of 74.\n\nTikTok has emerged as the new industry leader among major sites, edging past YouTube with a score of 78. This underscores the platform’s effective use of AI-driven content recommendations.\n\nMeta’s Facebook and Instagram have also seen significant improvements in user satisfaction, showing 3-point gains. While Facebook remains near the bottom of the industry at 69, Instagram’s score of 76 puts it within striking distance of the leaders.\n\nChallenges Remain\n\nDespite improvements, the study highlights ongoing privacy and advertising challenges for search engines and social media platforms. Privacy ratings for search engines remain relatively low but steady at 79, while social media platforms score even lower at 73.\n\nAdvertising experiences emerge as a key differentiator between higher- and lower-satisfaction brands, particularly in social media. New ACSI benchmarks reveal user concerns about advertising content’s trustworthiness and personal relevance.\n\nWhy This Matters For SEO Professionals\n\nThis study provides an independent perspective on how users are responding to the AI push in online services. For SEO professionals, these findings suggest that:\n\nAI-enhanced search features resonate with users, potentially changing search behavior and expectations. The improving satisfaction with alternative search engines like Bing may lead to a more diverse search landscape. The continued importance of factors like content freshness and site performance in user satisfaction aligns with long-standing SEO best practices.\n\nAs AI becomes more integrated into our online experiences, SEO strategies may need to adapt to changing user preferences.\n\nFeatured Image: kate3155/Shutterstock"
    },
    {
        "title": "OpenAI Launches SearchGPT: AI-Powered Search Prototype",
        "url": "https://www.searchenginejournal.com/openai-launches-searchgpt-ai-powered-search-prototype/523041/",
        "content": "OpenAI has announced the launch of SearchGPT, a prototype AI-powered search engine.\n\nThis move marks the company’s entry into the competitive search market, potentially challenging established players.\n\nKey Features & Functionality\n\nSearchGPT aims to directly answer user queries by combining AI language models with real-time web information.\n\nRather than offering a list of links, SearchGPT attempts to deliver concise responses with citations to source material.\n\nHere’s an example of a search results page for the query: “music festivals in boone north carolina in august.”\n\nThe SearchGPT prototype includes:\n\nA conversational interface allowing follow-up questions\n\nReal-time information retrieval from web sources\n\nIn-line attributions and links to original content\n\nPublisher Controls & Content Management\n\nOpenAI is also introducing tools for publishers to manage how their content appears in SearchGPT, giving them more control over their presence in AI-powered search results.\n\nKey points about the publisher controls include:\n\nSeparate from AI training: OpenAI emphasizes that SearchGPT is distinct from the training of their generative AI models. Sites can appear in search results even if they opt out of AI training data. Content management options: Publishers can influence how their content is displayed and used within SearchGPT. Feedback mechanism: OpenAI has provided an email (publishers-feedback@openai.com) for publishers to share their thoughts and concerns. Performance insights: The company plans to share information with publishers about their content’s performance within the AI search ecosystem.\n\nThese tools are OpenAI’s response to ongoing debates about AI’s use of web content and concerns over intellectual property rights.\n\nPublisher Partnerships & Reactions\n\nOpenAI reports collaborating with several publishers during the development of SearchGPT.\n\nNicholas Thompson, CEO of The Atlantic, provided a statement supporting the initiative, emphasizing the importance of valuing and protecting journalism in AI search development.\n\nRobert Thomson, News Corp’s chief executive, also commented on the project, stressing the need for a symbiotic relationship between technology and content and the importance of protecting content provenance.\n\nLimited Availability & Future Plans\n\nCurrently, SearchGPT is available to a restricted group of users and publishers.\n\nOpenAI describes it as a temporary prototype, indicating plans to integrate features into their existing ChatGPT product eventually.\n\nWhy This Matters\n\nThe introduction of SearchGPT represents a potential shakeup to the search engine market.\n\nThis development could have far-reaching implications for digital marketing, content creation, and user behavior on the internet.\n\nPotential effects include:\n\nChanges in content distribution and discovery mechanisms\n\nNew considerations for search engine optimization strategies\n\nEvolving relationships between AI companies and content creators\n\nRemember, this is still a prototype, and we have yet to see its capabilities.\n\nThere’s a waitlist available for those trying to get their hands on it early.\n\nWhat This Means For You\n\nAI-powered search might offer users more direct access to information. However, the accuracy and comprehensiveness of results may depend on publisher participation and content management choices.\n\nFor content creators and publishers, these new tools provide opportunities to have more say in how their work is used in AI search contexts.\n\nWhile it may increase content visibility and engagement, it also requires adapting to new formats and strategies to ensure content is AI-friendly and easily discoverable.\n\nAs SearchGPT moves from prototype to integration with ChatGPT, it will be vital to stay informed about these developments and adapt your strategies.\n\nThe future of search is evolving, and AI is at the forefront of this transformation."
    },
    {
        "title": "What Can AI Do For Healthcare Marketing In 2024?",
        "url": "https://www.searchenginejournal.com/callrail-ai-healthcare-marketing-2024-spa/522817/",
        "content": "This post was sponsored by CallRail. The opinions expressed in this article are the sponsor’s own.\n\nArtificial intelligence (AI) has huge potential for healthcare practices. It can assist with diagnosis and treatment, as well as administrative and marketing tasks. Yet, many practices are still wary of using AI, especially regarding marketing.\n\nThe reality is that AI is here to stay, and many healthcare practices are beginning to use the technology. According to one recent study, 89% of healthcare professionals surveyed said that they were at least evaluating AI products, experimenting with them, or had implemented AI.\n\nTo help you determine whether using AI is right for your healthcare practice, let’s take a look at some of the pros and cons of using AI while marketing.\n\nThe Pros And Cons Of AI For Healthcare Practices\n\nHealthcare practices that choose to implement AI in safe and appropriate ways to help them with their marketing and patient experience efforts can reap many benefits, including more leads, conversions, and satisfied patients. In fact, 41% of healthcare organizations say their marketing team already uses AI.\n\nPatients also expect healthcare practices to begin to implement AI in a number of ways. In one dentistry study, patients overall showed a positive attitude toward using AI. So, what’s holding your practice back from adding new tools and finding new use cases for AI? Let’s take a look at common concerns.\n\nCon #1: Data Security And Privacy Concerns\n\nLet’s get one of the biggest concerns with AI and healthcare out of the way first. Healthcare practices must follow all privacy and security regulations related to patients’ protected health information (PHI) to maintain HIPAA compliance.\n\nSo, concerns over whether AI can be used in a way that doesn’t interfere with HIPAA compliance are valid. In addition, there are also concerns about the open-source nature of popular GenAI models, which means sensitive practice data might be exposed to competitors or even hackers.\n\nPro #1: AI Can Help You Get More Value From Your Data Securely\n\nWhile there are valid concerns about how AI algorithms make decisions and data privacy concerns, AI can also be used to enrich data to help you achieve your marketing goals while still keeping it protected.\n\nWith appropriate guardrails and omission procedures in place, you can apply AI to gain insights from data that matters to you without putting sensitive data at risk.\n\nFor example, our CallRail Labs team is helping marketers remove their blind spots by using AI to analyze and detect critical context clues that help you qualify which calls are your best leads so you can follow up promptly.\n\nAt the same time, we know how important it is for healthcare companies to keep PHI secure, which is why we integrate with healthcare privacy platforms like Freshpaint. It can help you bridge the gap between patient privacy and digital marketing.\n\nIn addition, our AI-powered Healthcare Plan automatically redacts sensitive patient-protected health information from call transcripts, enforces obligatory log-outs to prevent PHI from becoming public, provides full audit trail logging, and even features unique logins and credentials for every user, which helps eliminate the potential for PHI to be accidentally exposed to employees who don’t need access to that information.\n\nCon #2: AI Is Impersonal\n\nHaving a good patient experience is important to almost all patients, and according to one survey, 52% of patients said a key part of a good patient experience is being treated with respect. Almost as many (46%) said they want to be addressed as a person. Given these concerns, handing over content creation or customer interactions to AI can feel daunting. While an AI-powered chatbot might be more efficient than a human in a call center, you also don’t want patients to feel like you’ve delegated customer service to a robot. Trust is the key to building patient relationships.\n\nPro #2: AI Can Improve The Patient Experience\n\nWorries over AI making patient interactions feel impersonal are reasonable, but just like any other type of tool, it’s how you use AI that matters. There are ways to deploy AI that can actually enhance the patient experience and, by doing so, give your healthcare practice an advantage over your competitors.\n\nThe answer isn’t in offloading customer interaction to chatbots. But AI can help you analyze customer interactions to make customer service more efficient and helpful.\n\nWith CallRail’s AI-powered Premium Conversation Intelligence™, which transcribes, summarizes, and analyzes each call, you can quickly assess your patients’ needs and concerns and respond appropriately with a human touch. For instance, Premium Conversation Intelligence can identify and extract common keywords and topics from call transcripts. This data reveals recurring themes, such as frequently asked questions, common complaints, and popular services. A healthcare practice could then use these insights to tailor their marketing campaigns to address the most pressing patient concerns.\n\nCon #3: AI Seems Too Complicated To Use\n\nLet’s face it: new technology is risky, and for healthcare practices especially, risk is scary. With AI, some of the risk comes from its perceived complexity. Identifying the right use cases for your practice, selecting the right tools, training your staff, and changing workflows can all feel quite daunting. Figuring this out takes time and money. And, if there aren’t clear use cases and ROI attached, the long-term benefits may not be worth the short-term impact on business.\n\nPro #3: AI Can Save Time And Money\n\nUsing a computer or a spreadsheet for the first time probably also felt complicated – and on the front end, took some time to learn. However, you know that using these tools, compared to pen, paper, and calculators, has saved an enormous amount of time, making the upfront investment clearly worth it. Compared to many technologies, AI tools are often intuitive and only require you to learn a few simple things like writing prompts, refining prompts, reviewing reports, etc. Even if it takes some time to learn new AI tools, the time savings will be worth it once you do.\n\nTo get the greatest return on investment, focus on AI solutions that take care of time-intensive tasks to free up time for innovation. With the right use cases and tools, AI can help solve complexity without adding complexity. For example, with Premium Conversation Intelligence, our customers spend 60% less time analyzing calls each week, and they’re using that time to train staff better, increase their productivity, and improve the patient experience.\n\nCon #4: AI Marketing Can Hurt Your Brand\n\nMany healthcare practices are excited to use GenAI tools to accelerate creative marketing efforts, like social media image creation and article writing. But consumers are less excited. In fact, consumers are more likely to say that the use of AI makes them distrusting (40%), rather than trusting (19%), of a brand. In a market where trust is the most important factor for patients when choosing healthcare providers, there is caution and hesitancy around using GenAI for marketing.\n\nPro #4: AI Helps Make Your Marketing Better\n\nWhile off-brand AI images shared on social media can be bad brand marketing, there are many ways AI can elevate your marketing efforts without impacting the brand perception. From uncovering insights to improving your marketing campaigns and maximizing the value of each marketing dollar spent to increasing lead conversion rates and decreasing patient churn, AI can help you tackle these problems faster and better than ever.\n\nAt CallRail, we’re using AI to tackle complex challenges like multi-conversation insights. CallRail can give marketers instant access to a 3-6 sentence summary for each call, average call sentiment, notable trends behind positive and negative interactions, and a summary of commonly asked questions. Such analysis would take hours and hours for your marketing team to do manually, but with AI, you have call insights at your fingertips to help drive messaging and keyword decisions that can improve your marketing attribution and the patient experience.\n\nCon #5: Adapting AI Tools Might Cause Disruption\n\nAs a modern healthcare practice, your tech stack is the engine that runs your business. When onboarding any new technology, there are always concerns about how well it will integrate with existing technology and tools you use and whether it supports HIPAA compliance. There may also be concern about how AI tools can fit into your existing workflows without causing disruption.\n\nPro #5: AI Helps People Do Their Jobs Better\n\nPairing the right AI tool for roles with repetitive tasks can be a win for your staff and your practice. For example, keeping up with healthcare trends is important for marketers to improve messaging and campaigns.\n\nAn AI-powered tool that analyzes conversations and provides call highlights can help healthcare marketers identify keyword and Google Ad opportunities so they can focus on implementing the most successful marketing strategy rather than listening to hours of call recordings. In addition, CallRail’s new AI-powered Convert Assist helps healthcare marketers provide a better patient experience. With AI-generated call coaching, marketers can identify what went well and what to improve after every conversation.\n\nWhat’s more, with a solution like CallRail, which offers a Healthcare Plan and will sign a business associate agreement (BAA), you are assured that we will comply with HIPAA controls within our service offerings to ensure that your call tracking doesn’t expose you to potential fines or litigation. Moreover, we also integrate with other marketing tools, like Google Ads, GA4, and more, making it easy to integrate our solution into your existing technologies and workflows.\n\nLet CallRail Show You The Pros Of AI\n\nIf you’re still worried about using AI in your healthcare practice, start with a trusted solution like CallRail that has proven ROI for AI-powered tools and a commitment to responsible AI development. You can talk to CallRail’s experts or test the product out for yourself with a 14-day free trial.\n\nImage Credits\n\nFeatured Image: Image by CallRail. Used with permission."
    },
    {
        "title": "Google Cautions On Blocking GoogleOther Bot",
        "url": "https://www.searchenginejournal.com/google-cautions-on-blocking-googleother-bot/523136/",
        "content": "Google’s Gary Illyes answered a question about the non-search features that the GoogleOther crawler supports, then added a caution about the consequences of blocking GoogleOther.\n\nWhat Is GoogleOther?\n\nGoogleOther is a generic crawler created by Google for the various purposes that fall outside of those of bots that specialize for Search, Ads, Video, Images, News, Desktop and Mobile. It can be used by internal teams at Google for research and development in relation to various products.\n\nThe official description of GoogleOther is:\n\n“GoogleOther is the generic crawler that may be used by various product teams for fetching publicly accessible content from sites. For example, it may be used for one-off crawls for internal research and development.”\n\nSomething that may be surprising is that there are actually three kinds of GoogleOther crawlers.\n\nThree Kinds Of GoogleOther Crawlers\n\nGoogleOther\n\nGeneric crawler for public URLs GoogleOther-Image\n\nOptimized to crawl public image URLs GoogleOther-Video\n\nOptimized to crawl public video URLs\n\nAll three GoogleOther crawlers can be used for research and development purposes. That’s just one purpose that Google publicly acknowledges that all three versions of GoogleOther could be used for.\n\nWhat Non-Search Features Does GoogleOther Support?\n\nGoogle doesn’t say what specific non-search features GoogleOther supports, probably because it doesn’t really “support” a specific feature. It exists for research and development crawling which could be in support of a new product or an improvement in a current product, it’s a highly open and generic purpose.\n\nThis is the question asked that Gary narrated:\n\n“What non-search features does GoogleOther crawling support?”\n\nGary Illyes answered:\n\n“This is a very topical question, and I think it is a very good question. Besides what’s in the public I don’t have more to share. GoogleOther is the generic crawler that may be used by various product teams for fetching publicly accessible content from sites. For example, it may be used for one-off crawls for internal research and development. Historically Googlebot was used for this, but that kind of makes things murky and less transparent, so we launched GoogleOther so you have better controls over what your site is crawled for. That said GoogleOther is not tied to a single product, so opting out of GoogleOther crawling might affect a wide range of things across the Google universe; alas, not Search, search is only Googlebot.”\n\nIt Might Affect A Wide Range Of Things\n\nGary is clear that blocking GoogleOther wouldn’t have an affect on Google Search because Googlebot is the crawler used for indexing content. So if blocking any of the three versions of GoogleOther is something a site owner wants to do, then it should be okay to do that without a negative effect on search rankings.\n\nBut Gary also cautioned about the outcome that blocking GoogleOther, saying that it would have an effect on other products and services across Google. He didn’t state which other products it could affect nor did he elaborate on the pros or cons of blocking GoogleOther.\n\nPros And Cons Of Blocking GoogleOther\n\nWhether or not to block GoogleOther doesn’t necessarily have a straightforward answer. There are several considerations to whether doing that makes sense.\n\nPros\n\nInclusion in research for a future Google product that’s related to search (maps, shopping, images, a new feature in search) could be useful. It might be helpful to have a site included in that kind of research because it might be used for testing something good for a site and be one of the few sites chosen to test a feature that could increase earnings for a site.\n\nAnother consideration is that blocking GoogleOther to save on server resources is not necessarily a valid reason because GoogleOther doesn’t seem to crawl so often that it makes a noticeable impact.\n\nIf blocking Google from using site content for AI is a concern then blocking GoogleOther will have no impact on that at all. GoogleOther has nothing to do with crawling for Google Gemini apps or Vertex AI, including any future products that will be used for training associated language models. The bot for that specific use case is Google-Extended.\n\nCons\n\nOn the other hand it might not be helpful to allow GoogleOther if it’s being used to test something related to fighting spam and there’s something the site has to hide.\n\nIt’s possible that a site owner might not want to participate if GoogleOther comes crawling for market research or for training machine learning models (for internal purposes) that are unrelated to public-facing products like Gemini and Vertex.\n\nAllowing GoogleOther to crawl a site for unknown purposes is like giving Google a blank check to use your site data in any way they see fit outside of training public-facing LLMs or purposes related to named bots like GoogleBot.\n\nTakeaway\n\nShould you block GoogleOther? It’s a coin toss. There are possible potential benefits but in general there isn’t enough information to make an informed decision.\n\nListen to the Google SEO Office Hours podcast at the 1:30 minute mark:\n\nFeatured Image by Shutterstock/Cast Of Thousands"
    },
    {
        "title": "Find Keyword Cannibalization Using OpenAI’s Text Embeddings With Examples",
        "url": "https://www.searchenginejournal.com/find-keyword-cannibalization-using-openai-text-embeddings-examples/520274/",
        "content": "This new series of articles focuses on working with LLMs to scale your SEO tasks. We hope to help you integrate AI into SEO so you can level up your skills.\n\nWe hope you enjoyed the previous article and understand what vectors, vector distance, and text embeddings are.\n\nFollowing this, it’s time to flex your “AI knowledge muscles” by learning how to use text embeddings to find keyword cannibalization.\n\nWe will start with OpenAI’s text embeddings and compare them.\n\nModel Dimensionality Pricing Notes text-embedding-ada-002 1536 $0.10 per 1M tokens Great for most use cases. text-embedding-3-small 1536 $0.002 per 1M tokens Faster and cheaper but less accurate text-embedding-3-large 3072 $0.13 per 1M tokens More accurate for complex long text-related tasks, slower\n\n(*tokens can be considered as words words.)\n\nBut before we start, you need to install Python and Jupyter on your computer.\n\nJupyter is a web-based tool for professionals and researchers. It allows you to perform complex data analysis and machine learning model development using any programming language.\n\nDon’t worry – it’s really easy and takes little time to finish the installations. And remember, ChatGPT is your friend when it comes to programming.\n\nIn a nutshell:\n\nDownload and install Python.\n\nOpen your Windows command line or terminal on Mac.\n\nType this commands pip install jupyterlab and pip install notebook\n\nand Run Jupiter by this command: jupyter lab\n\nWe will use Jupyter to experiment with text embeddings; you’ll see how fun it is to work with!\n\nBut before we start, you must sign up for OpenAI’s API and set up billing by filling your balance.\n\nOnce you’ve done that, set up email notifications to inform you when your spending exceeds a certain amount under Usage limits.\n\nThen, obtain API keys under Dashboard > API keys, which you should keep private and never share publicly.\n\nNow, you have all the necessary tools to start playing with embeddings.\n\nOpen your computer command terminal and type jupyter lab .\n\n. You should see something like the below image pop up in your browser.\n\nClick on Python 3 under Notebook.\n\nIn the opened window, you will write your code.\n\nAs a small task, let’s group similar URLs from a CSV. The sample CSV has two columns: URL and Title. Our script’s task will be to group URLs with similar semantic meanings based on the title so we can consolidate those pages into one and fix keyword cannibalization issues.\n\nHere are the steps you need to do:\n\nInstall required Python libraries with the following commands in your PC’s terminal (or in Jupyter notebook)\n\npip install pandas openai scikit-learn numpy unidecode\n\nThe ‘openai’ library is required to interact with the OpenAI API to get embeddings, and ‘pandas’ is used for data manipulation and handling CSV file operations.\n\nThe ‘scikit-learn’ library is necessary for calculating cosine similarity, and ‘numpy’ is essential for numerical operations and handling arrays. Lastly, unidecode is used to clean text.\n\nThen, download the sample sheet as a CSV, rename the file to pages.csv, and upload it to your Jupyter folder where your script is located.\n\nSet your OpenAI API key to the key you obtained in the step above, and copy-paste the code below into the notebook.\n\nRun the code by clicking the play triangle icon at the top of the notebook.\n\nimport pandas as pd import openai from sklearn.metrics.pairwise import cosine_similarity import numpy as np import csv from unidecode import unidecode # Function to clean text def clean_text(text: str) -> str: # First, replace known problematic characters with their correct equivalents replacements = { 'â€“': '–', # en dash 'â€™': '’', # right single quotation mark 'â€œ': '“', # left double quotation mark 'â€': '”', # right double quotation mark 'â€˜': '‘', # left single quotation mark 'â€': '—' # em dash } for old, new in replacements.items(): text = text.replace(old, new) # Then, use unidecode to transliterate any remaining problematic Unicode characters text = unidecode(text) return text # Load the CSV file with UTF-8 encoding from root folder of Jupiter project folder df = pd.read_csv('pages.csv', encoding='utf-8') # Clean the 'Title' column to remove unwanted symbols df['Title'] = df['Title'].apply(clean_text) # Set your OpenAI API key openai.api_key = 'your-api-key-goes-here' # Function to get embeddings def get_embedding(text): response = openai.Embedding.create(input=[text], engine=\"text-embedding-ada-002\") return response['data'][0]['embedding'] # Generate embeddings for all titles df['embedding'] = df['Title'].apply(get_embedding) # Create a matrix of embeddings embedding_matrix = np.vstack(df['embedding'].values) # Compute cosine similarity matrix similarity_matrix = cosine_similarity(embedding_matrix) # Define similarity threshold similarity_threshold = 0.9 # since threshold is 0.1 for dissimilarity # Create a list to store groups groups = [] # Keep track of visited indices visited = set() # Group similar titles based on the similarity matrix for i in range(len(similarity_matrix)): if i not in visited: # Find all similar titles similar_indices = np.where(similarity_matrix[i] >= similarity_threshold)[0] # Log comparisons print(f\"\n\nChecking similarity for '{df.iloc[i]['Title']}' (Index {i}):\") print(\"-\" * 50) for j in range(len(similarity_matrix)): if i != j: # Ensure that a title is not compared with itself similarity_value = similarity_matrix[i, j] comparison_result = 'greater' if similarity_value >= similarity_threshold else 'less' print(f\"Compared with '{df.iloc[j]['Title']}' (Index {j}): similarity = {similarity_value:.4f} ({comparison_result} than threshold)\") # Add these indices to visited visited.update(similar_indices) # Add the group to the list group = df.iloc[similar_indices][['URL', 'Title']].to_dict('records') groups.append(group) print(f\"\n\nFormed Group {len(groups)}:\") for item in group: print(f\" - URL: {item['URL']}, Title: {item['Title']}\") # Check if groups were created if not groups: print(\"No groups were created.\") # Define the output CSV file output_file = 'grouped_pages.csv' # Write the results to the CSV file with UTF-8 encoding with open(output_file, 'w', newline='', encoding='utf-8') as csvfile: fieldnames = ['Group', 'URL', 'Title'] writer = csv.DictWriter(csvfile, fieldnames=fieldnames) writer.writeheader() for group_index, group in enumerate(groups, start=1): for page in group: cleaned_title = clean_text(page['Title']) # Ensure no unwanted symbols in the output writer.writerow({'Group': group_index, 'URL': page['URL'], 'Title': cleaned_title}) print(f\"Writing Group {group_index}, URL: {page['URL']}, Title: {cleaned_title}\") print(f\"Output written to {output_file}\")\n\nThis code reads a CSV file, ‘pages.csv,’ containing titles and URLs, which you can easily export from your CMS or get by crawling a client website using Screaming Frog.\n\nThen, it cleans the titles from non-UTF characters, generates embedding vectors for each title using OpenAI’s API, calculates the similarity between the titles, groups similar titles together, and writes the grouped results to a new CSV file, ‘grouped_pages.csv.’\n\nIn the keyword cannibalization task, we use a similarity threshold of 0.9, which means if cosine similarity is less than 0.9, we will consider articles as different. To visualize this in a simplified two-dimensional space, it will appear as two vectors with an angle of approximately 25 degrees between them.\n\nIn your case, you may want to use a different threshold, like 0.85 (approximately 31 degrees between them), and run it on a sample of your data to evaluate the results and the overall quality of matches. If it is unsatisfactory, you can increase the threshold to make it more strict for better precision.\n\nYou can install ‘matplotlib’ via terminal.\n\npip install matplotlib\n\nAnd use the Python code below in a separate Jupyter notebook to visualize cosine similarities in two-dimensional space on your own. Try it; it’s fun!\n\nimport matplotlib.pyplot as plt import numpy as np # Define the angle for cosine similarity of 0.9. Change here to your desired value. theta = np.arccos(0.9) # Define the vectors u = np.array([1, 0]) v = np.array([np.cos(theta), np.sin(theta)]) # Define the 45 degree rotation matrix rotation_matrix = np.array([ [np.cos(np.pi/4), -np.sin(np.pi/4)], [np.sin(np.pi/4), np.cos(np.pi/4)] ]) # Apply the rotation to both vectors u_rotated = np.dot(rotation_matrix, u) v_rotated = np.dot(rotation_matrix, v) # Plotting the vectors plt.figure() plt.quiver(0, 0, u_rotated[0], u_rotated[1], angles='xy', scale_units='xy', scale=1, color='r') plt.quiver(0, 0, v_rotated[0], v_rotated[1], angles='xy', scale_units='xy', scale=1, color='b') # Setting the plot limits to only positive ranges plt.xlim(0, 1.5) plt.ylim(0, 1.5) # Adding labels and grid plt.xlabel('X-axis') plt.ylabel('Y-axis') plt.grid(True) plt.title('Visualization of Vectors with Cosine Similarity of 0.9') # Show the plot plt.show()\n\nI usually use 0.9 and higher for identifying keyword cannibalization issues, but you may need to set it to 0.5 when dealing with old article redirects, as old articles may not have nearly identical articles that are fresher but partially close.\n\nIt may also be better to have the meta description concatenated with the title in case of redirects, in addition to the title.\n\nSo, it depends on the task you are performing. We will review how to implement redirects in a separate article later in this series.\n\nNow, let’s review the results with the three models mentioned above and see how they were able to identify close articles from our data sample from Search Engine Journal’s articles.\n\nFrom the list, we already see that the 2nd and 4th articles cover the same topic on ‘meta tags.’ The articles in the 5th and 7th rows are pretty much the same – discussing the importance of H1 tags in SEO – and can be merged.\n\nThe article in the 3rd row doesn’t have any similarities with any of the articles in the list but has common words like “Tag” or “SEO.”\n\nThe article in the 6th row is again about H1, but not exactly the same as H1’s importance to SEO. Instead, it represents Google’s opinion on whether they should match.\n\nArticles on the 8th and 9th rows are quite close but still different; they can be combined.\n\ntext-embedding-ada-002\n\nBy using ‘text-embedding-ada-002,’ we precisely found the 2nd and 4th articles with a cosine similarity of 0.92 and the 5th and 7th articles with a similarity of 0.91.\n\nAnd it generated output with grouped URLs by using the same group number for similar articles. (colors are applied manually for visualization purposes).\n\nFor the 2nd and 3rd articles, which have common words “Tag” and “SEO” but are unrelated, the cosine similarity was 0.86. This shows why a high similarity threshold of 0.9 or greater is necessary. If we set it to 0.85, it would be full of false positives and could suggest merging unrelated articles.\n\ntext-embedding-3-small\n\nBy using ‘text-embedding-3-small,’ quite surprisingly, it didn’t find any matches per our similarity threshold of 0.9 or higher.\n\nFor the 2nd and 4th articles, cosine similarity was 0.76, and for the 5th and 7th articles, with similarity 0.77.\n\nTo better understand this model through experimentation, I’ve added a slightly modified version of the 1st row with ’15’ vs. ’14’ to the sample.\n\n“14 Most Important Meta And HTML Tags You Need To Know For SEO” “15 Most Important Meta And HTML Tags You Need To Know For SEO”\n\nOn the contrary, ‘text-embedding-ada-002’ gave 0.98 cosine similarity between those versions.\n\nTitle 1 Title 2 Cosine Similarity 14 Most Important Meta And HTML Tags You Need To Know For SEO 15 Most Important Meta And HTML Tags You Need To Know For SEO 0.92 14 Most Important Meta And HTML Tags You Need To Know For SEO Meta Tags: What You Need To Know For SEO 0.76\n\nHere, we see that this model is not quite a good fit for comparing titles.\n\ntext-embedding-3-large\n\nThis model’s dimensionality is 3072, which is 2 times higher than that of ‘text-embedding-3-small’ and ‘text-embedding-ada-002′, with 1536 dimensionality.\n\nAs it has more dimensions than the other models, we could expect it to capture semantic meaning with higher precision.\n\nHowever, it gave the 2nd and 4th articles cosine similarity of 0.70 and the 5th and 7th articles similarity of 0.75.\n\nI’ve tested it again with slightly modified versions of the first article with ’15’ vs. ’14’ and without ‘Most Important’ in the title.\n\n“14 Most Important Meta And HTML Tags You Need To Know For SEO” “15 Most Important Meta And HTML Tags You Need To Know For SEO” “14 Meta And HTML Tags You Need To Know For SEO”\n\nTitle 1 Title 2 Cosine Similarity 14 Most Important Meta And HTML Tags You Need To Know For SEO 15 Most Important Meta And HTML Tags You Need To Know For SEO 0.95 14 Most Important Meta And HTML Tags You Need To Know For SEO 14 Most Important Meta And HTML Tags You Need To Know For SEO 0.93 14 Most Important Meta And HTML Tags You Need To Know For SEO Meta Tags: What You Need To Know For SEO 0.70 15 Most Important Meta And HTML Tags You Need To Know For SEO 14 Most Important Meta And HTML Tags You Need To Know For SEO 0.86\n\nSo we can see that ‘text-embedding-3-large’ is underperforming compared to ‘text-embedding-ada-002’ when we calculate cosine similarities between titles.\n\nI want to note that the accuracy of ‘text-embedding-3-large’ increases with the length of the text, but ‘text-embedding-ada-002’ still performs better overall.\n\nAnother approach could be to strip away stop words from the text. Removing these can sometimes help focus the embeddings on more meaningful words, potentially improving the accuracy of tasks like similarity calculations.\n\nThe best way to determine whether removing stop words improves accuracy for your specific task and dataset is to empirically test both approaches and compare the results.\n\nConclusion\n\nWith these examples, you have learned how to work with OpenAI’s embedding models and can already perform a wide range of tasks.\n\nFor similarity thresholds, you need to experiment with your own datasets and see which thresholds make sense for your specific task by running it on smaller samples of data and performing a human review of the output.\n\nPlease note that the code we have in this article is not optimal for large datasets since you need to create text embeddings of articles every time there is a change in your dataset to evaluate against other rows.\n\nTo make it efficient, we must use vector databases and store embedding information there once generated. We will cover how to use vector databases very soon and change the code sample here to use a vector database.\n\nMore resources:\n\nFeatured Image: BestForBest/Shutterstock"
    },
    {
        "title": "Google Cautions On Blocking GoogleOther Bot",
        "url": "https://www.searchenginejournal.com/google-cautions-on-blocking-googleother-bot/523136/",
        "content": "Google’s Gary Illyes answered a question about the non-search features that the GoogleOther crawler supports, then added a caution about the consequences of blocking GoogleOther.\n\nWhat Is GoogleOther?\n\nGoogleOther is a generic crawler created by Google for the various purposes that fall outside of those of bots that specialize for Search, Ads, Video, Images, News, Desktop and Mobile. It can be used by internal teams at Google for research and development in relation to various products.\n\nThe official description of GoogleOther is:\n\n“GoogleOther is the generic crawler that may be used by various product teams for fetching publicly accessible content from sites. For example, it may be used for one-off crawls for internal research and development.”\n\nSomething that may be surprising is that there are actually three kinds of GoogleOther crawlers.\n\nThree Kinds Of GoogleOther Crawlers\n\nGoogleOther\n\nGeneric crawler for public URLs GoogleOther-Image\n\nOptimized to crawl public image URLs GoogleOther-Video\n\nOptimized to crawl public video URLs\n\nAll three GoogleOther crawlers can be used for research and development purposes. That’s just one purpose that Google publicly acknowledges that all three versions of GoogleOther could be used for.\n\nWhat Non-Search Features Does GoogleOther Support?\n\nGoogle doesn’t say what specific non-search features GoogleOther supports, probably because it doesn’t really “support” a specific feature. It exists for research and development crawling which could be in support of a new product or an improvement in a current product, it’s a highly open and generic purpose.\n\nThis is the question asked that Gary narrated:\n\n“What non-search features does GoogleOther crawling support?”\n\nGary Illyes answered:\n\n“This is a very topical question, and I think it is a very good question. Besides what’s in the public I don’t have more to share. GoogleOther is the generic crawler that may be used by various product teams for fetching publicly accessible content from sites. For example, it may be used for one-off crawls for internal research and development. Historically Googlebot was used for this, but that kind of makes things murky and less transparent, so we launched GoogleOther so you have better controls over what your site is crawled for. That said GoogleOther is not tied to a single product, so opting out of GoogleOther crawling might affect a wide range of things across the Google universe; alas, not Search, search is only Googlebot.”\n\nIt Might Affect A Wide Range Of Things\n\nGary is clear that blocking GoogleOther wouldn’t have an affect on Google Search because Googlebot is the crawler used for indexing content. So if blocking any of the three versions of GoogleOther is something a site owner wants to do, then it should be okay to do that without a negative effect on search rankings.\n\nBut Gary also cautioned about the outcome that blocking GoogleOther, saying that it would have an effect on other products and services across Google. He didn’t state which other products it could affect nor did he elaborate on the pros or cons of blocking GoogleOther.\n\nPros And Cons Of Blocking GoogleOther\n\nWhether or not to block GoogleOther doesn’t necessarily have a straightforward answer. There are several considerations to whether doing that makes sense.\n\nPros\n\nInclusion in research for a future Google product that’s related to search (maps, shopping, images, a new feature in search) could be useful. It might be helpful to have a site included in that kind of research because it might be used for testing something good for a site and be one of the few sites chosen to test a feature that could increase earnings for a site.\n\nAnother consideration is that blocking GoogleOther to save on server resources is not necessarily a valid reason because GoogleOther doesn’t seem to crawl so often that it makes a noticeable impact.\n\nIf blocking Google from using site content for AI is a concern then blocking GoogleOther will have no impact on that at all. GoogleOther has nothing to do with crawling for Google Gemini apps or Vertex AI, including any future products that will be used for training associated language models. The bot for that specific use case is Google-Extended.\n\nCons\n\nOn the other hand it might not be helpful to allow GoogleOther if it’s being used to test something related to fighting spam and there’s something the site has to hide.\n\nIt’s possible that a site owner might not want to participate if GoogleOther comes crawling for market research or for training machine learning models (for internal purposes) that are unrelated to public-facing products like Gemini and Vertex.\n\nAllowing GoogleOther to crawl a site for unknown purposes is like giving Google a blank check to use your site data in any way they see fit outside of training public-facing LLMs or purposes related to named bots like GoogleBot.\n\nTakeaway\n\nShould you block GoogleOther? It’s a coin toss. There are possible potential benefits but in general there isn’t enough information to make an informed decision.\n\nListen to the Google SEO Office Hours podcast at the 1:30 minute mark:\n\nFeatured Image by Shutterstock/Cast Of Thousands"
    },
    {
        "title": "Find Keyword Cannibalization Using OpenAI’s Text Embeddings With Examples",
        "url": "https://www.searchenginejournal.com/find-keyword-cannibalization-using-openai-text-embeddings-examples/520274/",
        "content": "This new series of articles focuses on working with LLMs to scale your SEO tasks. We hope to help you integrate AI into SEO so you can level up your skills.\n\nWe hope you enjoyed the previous article and understand what vectors, vector distance, and text embeddings are.\n\nFollowing this, it’s time to flex your “AI knowledge muscles” by learning how to use text embeddings to find keyword cannibalization.\n\nWe will start with OpenAI’s text embeddings and compare them.\n\nModel Dimensionality Pricing Notes text-embedding-ada-002 1536 $0.10 per 1M tokens Great for most use cases. text-embedding-3-small 1536 $0.002 per 1M tokens Faster and cheaper but less accurate text-embedding-3-large 3072 $0.13 per 1M tokens More accurate for complex long text-related tasks, slower\n\n(*tokens can be considered as words words.)\n\nBut before we start, you need to install Python and Jupyter on your computer.\n\nJupyter is a web-based tool for professionals and researchers. It allows you to perform complex data analysis and machine learning model development using any programming language.\n\nDon’t worry – it’s really easy and takes little time to finish the installations. And remember, ChatGPT is your friend when it comes to programming.\n\nIn a nutshell:\n\nDownload and install Python.\n\nOpen your Windows command line or terminal on Mac.\n\nType this commands pip install jupyterlab and pip install notebook\n\nand Run Jupiter by this command: jupyter lab\n\nWe will use Jupyter to experiment with text embeddings; you’ll see how fun it is to work with!\n\nBut before we start, you must sign up for OpenAI’s API and set up billing by filling your balance.\n\nOnce you’ve done that, set up email notifications to inform you when your spending exceeds a certain amount under Usage limits.\n\nThen, obtain API keys under Dashboard > API keys, which you should keep private and never share publicly.\n\nNow, you have all the necessary tools to start playing with embeddings.\n\nOpen your computer command terminal and type jupyter lab .\n\n. You should see something like the below image pop up in your browser.\n\nClick on Python 3 under Notebook.\n\nIn the opened window, you will write your code.\n\nAs a small task, let’s group similar URLs from a CSV. The sample CSV has two columns: URL and Title. Our script’s task will be to group URLs with similar semantic meanings based on the title so we can consolidate those pages into one and fix keyword cannibalization issues.\n\nHere are the steps you need to do:\n\nInstall required Python libraries with the following commands in your PC’s terminal (or in Jupyter notebook)\n\npip install pandas openai scikit-learn numpy unidecode\n\nThe ‘openai’ library is required to interact with the OpenAI API to get embeddings, and ‘pandas’ is used for data manipulation and handling CSV file operations.\n\nThe ‘scikit-learn’ library is necessary for calculating cosine similarity, and ‘numpy’ is essential for numerical operations and handling arrays. Lastly, unidecode is used to clean text.\n\nThen, download the sample sheet as a CSV, rename the file to pages.csv, and upload it to your Jupyter folder where your script is located.\n\nSet your OpenAI API key to the key you obtained in the step above, and copy-paste the code below into the notebook.\n\nRun the code by clicking the play triangle icon at the top of the notebook.\n\nimport pandas as pd import openai from sklearn.metrics.pairwise import cosine_similarity import numpy as np import csv from unidecode import unidecode # Function to clean text def clean_text(text: str) -> str: # First, replace known problematic characters with their correct equivalents replacements = { 'â€“': '–', # en dash 'â€™': '’', # right single quotation mark 'â€œ': '“', # left double quotation mark 'â€': '”', # right double quotation mark 'â€˜': '‘', # left single quotation mark 'â€': '—' # em dash } for old, new in replacements.items(): text = text.replace(old, new) # Then, use unidecode to transliterate any remaining problematic Unicode characters text = unidecode(text) return text # Load the CSV file with UTF-8 encoding from root folder of Jupiter project folder df = pd.read_csv('pages.csv', encoding='utf-8') # Clean the 'Title' column to remove unwanted symbols df['Title'] = df['Title'].apply(clean_text) # Set your OpenAI API key openai.api_key = 'your-api-key-goes-here' # Function to get embeddings def get_embedding(text): response = openai.Embedding.create(input=[text], engine=\"text-embedding-ada-002\") return response['data'][0]['embedding'] # Generate embeddings for all titles df['embedding'] = df['Title'].apply(get_embedding) # Create a matrix of embeddings embedding_matrix = np.vstack(df['embedding'].values) # Compute cosine similarity matrix similarity_matrix = cosine_similarity(embedding_matrix) # Define similarity threshold similarity_threshold = 0.9 # since threshold is 0.1 for dissimilarity # Create a list to store groups groups = [] # Keep track of visited indices visited = set() # Group similar titles based on the similarity matrix for i in range(len(similarity_matrix)): if i not in visited: # Find all similar titles similar_indices = np.where(similarity_matrix[i] >= similarity_threshold)[0] # Log comparisons print(f\"\n\nChecking similarity for '{df.iloc[i]['Title']}' (Index {i}):\") print(\"-\" * 50) for j in range(len(similarity_matrix)): if i != j: # Ensure that a title is not compared with itself similarity_value = similarity_matrix[i, j] comparison_result = 'greater' if similarity_value >= similarity_threshold else 'less' print(f\"Compared with '{df.iloc[j]['Title']}' (Index {j}): similarity = {similarity_value:.4f} ({comparison_result} than threshold)\") # Add these indices to visited visited.update(similar_indices) # Add the group to the list group = df.iloc[similar_indices][['URL', 'Title']].to_dict('records') groups.append(group) print(f\"\n\nFormed Group {len(groups)}:\") for item in group: print(f\" - URL: {item['URL']}, Title: {item['Title']}\") # Check if groups were created if not groups: print(\"No groups were created.\") # Define the output CSV file output_file = 'grouped_pages.csv' # Write the results to the CSV file with UTF-8 encoding with open(output_file, 'w', newline='', encoding='utf-8') as csvfile: fieldnames = ['Group', 'URL', 'Title'] writer = csv.DictWriter(csvfile, fieldnames=fieldnames) writer.writeheader() for group_index, group in enumerate(groups, start=1): for page in group: cleaned_title = clean_text(page['Title']) # Ensure no unwanted symbols in the output writer.writerow({'Group': group_index, 'URL': page['URL'], 'Title': cleaned_title}) print(f\"Writing Group {group_index}, URL: {page['URL']}, Title: {cleaned_title}\") print(f\"Output written to {output_file}\")\n\nThis code reads a CSV file, ‘pages.csv,’ containing titles and URLs, which you can easily export from your CMS or get by crawling a client website using Screaming Frog.\n\nThen, it cleans the titles from non-UTF characters, generates embedding vectors for each title using OpenAI’s API, calculates the similarity between the titles, groups similar titles together, and writes the grouped results to a new CSV file, ‘grouped_pages.csv.’\n\nIn the keyword cannibalization task, we use a similarity threshold of 0.9, which means if cosine similarity is less than 0.9, we will consider articles as different. To visualize this in a simplified two-dimensional space, it will appear as two vectors with an angle of approximately 25 degrees between them.\n\nIn your case, you may want to use a different threshold, like 0.85 (approximately 31 degrees between them), and run it on a sample of your data to evaluate the results and the overall quality of matches. If it is unsatisfactory, you can increase the threshold to make it more strict for better precision.\n\nYou can install ‘matplotlib’ via terminal.\n\npip install matplotlib\n\nAnd use the Python code below in a separate Jupyter notebook to visualize cosine similarities in two-dimensional space on your own. Try it; it’s fun!\n\nimport matplotlib.pyplot as plt import numpy as np # Define the angle for cosine similarity of 0.9. Change here to your desired value. theta = np.arccos(0.9) # Define the vectors u = np.array([1, 0]) v = np.array([np.cos(theta), np.sin(theta)]) # Define the 45 degree rotation matrix rotation_matrix = np.array([ [np.cos(np.pi/4), -np.sin(np.pi/4)], [np.sin(np.pi/4), np.cos(np.pi/4)] ]) # Apply the rotation to both vectors u_rotated = np.dot(rotation_matrix, u) v_rotated = np.dot(rotation_matrix, v) # Plotting the vectors plt.figure() plt.quiver(0, 0, u_rotated[0], u_rotated[1], angles='xy', scale_units='xy', scale=1, color='r') plt.quiver(0, 0, v_rotated[0], v_rotated[1], angles='xy', scale_units='xy', scale=1, color='b') # Setting the plot limits to only positive ranges plt.xlim(0, 1.5) plt.ylim(0, 1.5) # Adding labels and grid plt.xlabel('X-axis') plt.ylabel('Y-axis') plt.grid(True) plt.title('Visualization of Vectors with Cosine Similarity of 0.9') # Show the plot plt.show()\n\nI usually use 0.9 and higher for identifying keyword cannibalization issues, but you may need to set it to 0.5 when dealing with old article redirects, as old articles may not have nearly identical articles that are fresher but partially close.\n\nIt may also be better to have the meta description concatenated with the title in case of redirects, in addition to the title.\n\nSo, it depends on the task you are performing. We will review how to implement redirects in a separate article later in this series.\n\nNow, let’s review the results with the three models mentioned above and see how they were able to identify close articles from our data sample from Search Engine Journal’s articles.\n\nFrom the list, we already see that the 2nd and 4th articles cover the same topic on ‘meta tags.’ The articles in the 5th and 7th rows are pretty much the same – discussing the importance of H1 tags in SEO – and can be merged.\n\nThe article in the 3rd row doesn’t have any similarities with any of the articles in the list but has common words like “Tag” or “SEO.”\n\nThe article in the 6th row is again about H1, but not exactly the same as H1’s importance to SEO. Instead, it represents Google’s opinion on whether they should match.\n\nArticles on the 8th and 9th rows are quite close but still different; they can be combined.\n\ntext-embedding-ada-002\n\nBy using ‘text-embedding-ada-002,’ we precisely found the 2nd and 4th articles with a cosine similarity of 0.92 and the 5th and 7th articles with a similarity of 0.91.\n\nAnd it generated output with grouped URLs by using the same group number for similar articles. (colors are applied manually for visualization purposes).\n\nFor the 2nd and 3rd articles, which have common words “Tag” and “SEO” but are unrelated, the cosine similarity was 0.86. This shows why a high similarity threshold of 0.9 or greater is necessary. If we set it to 0.85, it would be full of false positives and could suggest merging unrelated articles.\n\ntext-embedding-3-small\n\nBy using ‘text-embedding-3-small,’ quite surprisingly, it didn’t find any matches per our similarity threshold of 0.9 or higher.\n\nFor the 2nd and 4th articles, cosine similarity was 0.76, and for the 5th and 7th articles, with similarity 0.77.\n\nTo better understand this model through experimentation, I’ve added a slightly modified version of the 1st row with ’15’ vs. ’14’ to the sample.\n\n“14 Most Important Meta And HTML Tags You Need To Know For SEO” “15 Most Important Meta And HTML Tags You Need To Know For SEO”\n\nOn the contrary, ‘text-embedding-ada-002’ gave 0.98 cosine similarity between those versions.\n\nTitle 1 Title 2 Cosine Similarity 14 Most Important Meta And HTML Tags You Need To Know For SEO 15 Most Important Meta And HTML Tags You Need To Know For SEO 0.92 14 Most Important Meta And HTML Tags You Need To Know For SEO Meta Tags: What You Need To Know For SEO 0.76\n\nHere, we see that this model is not quite a good fit for comparing titles.\n\ntext-embedding-3-large\n\nThis model’s dimensionality is 3072, which is 2 times higher than that of ‘text-embedding-3-small’ and ‘text-embedding-ada-002′, with 1536 dimensionality.\n\nAs it has more dimensions than the other models, we could expect it to capture semantic meaning with higher precision.\n\nHowever, it gave the 2nd and 4th articles cosine similarity of 0.70 and the 5th and 7th articles similarity of 0.75.\n\nI’ve tested it again with slightly modified versions of the first article with ’15’ vs. ’14’ and without ‘Most Important’ in the title.\n\n“14 Most Important Meta And HTML Tags You Need To Know For SEO” “15 Most Important Meta And HTML Tags You Need To Know For SEO” “14 Meta And HTML Tags You Need To Know For SEO”\n\nTitle 1 Title 2 Cosine Similarity 14 Most Important Meta And HTML Tags You Need To Know For SEO 15 Most Important Meta And HTML Tags You Need To Know For SEO 0.95 14 Most Important Meta And HTML Tags You Need To Know For SEO 14 Most Important Meta And HTML Tags You Need To Know For SEO 0.93 14 Most Important Meta And HTML Tags You Need To Know For SEO Meta Tags: What You Need To Know For SEO 0.70 15 Most Important Meta And HTML Tags You Need To Know For SEO 14 Most Important Meta And HTML Tags You Need To Know For SEO 0.86\n\nSo we can see that ‘text-embedding-3-large’ is underperforming compared to ‘text-embedding-ada-002’ when we calculate cosine similarities between titles.\n\nI want to note that the accuracy of ‘text-embedding-3-large’ increases with the length of the text, but ‘text-embedding-ada-002’ still performs better overall.\n\nAnother approach could be to strip away stop words from the text. Removing these can sometimes help focus the embeddings on more meaningful words, potentially improving the accuracy of tasks like similarity calculations.\n\nThe best way to determine whether removing stop words improves accuracy for your specific task and dataset is to empirically test both approaches and compare the results.\n\nConclusion\n\nWith these examples, you have learned how to work with OpenAI’s embedding models and can already perform a wide range of tasks.\n\nFor similarity thresholds, you need to experiment with your own datasets and see which thresholds make sense for your specific task by running it on smaller samples of data and performing a human review of the output.\n\nPlease note that the code we have in this article is not optimal for large datasets since you need to create text embeddings of articles every time there is a change in your dataset to evaluate against other rows.\n\nTo make it efficient, we must use vector databases and store embedding information there once generated. We will cover how to use vector databases very soon and change the code sample here to use a vector database.\n\nMore resources:\n\nFeatured Image: BestForBest/Shutterstock"
    },
    {
        "title": "OpenAI Launches SearchGPT: AI-Powered Search Prototype",
        "url": "https://www.searchenginejournal.com/openai-launches-searchgpt-ai-powered-search-prototype/523041/",
        "content": "OpenAI has announced the launch of SearchGPT, a prototype AI-powered search engine.\n\nThis move marks the company’s entry into the competitive search market, potentially challenging established players.\n\nKey Features & Functionality\n\nSearchGPT aims to directly answer user queries by combining AI language models with real-time web information.\n\nRather than offering a list of links, SearchGPT attempts to deliver concise responses with citations to source material.\n\nHere’s an example of a search results page for the query: “music festivals in boone north carolina in august.”\n\nThe SearchGPT prototype includes:\n\nA conversational interface allowing follow-up questions\n\nReal-time information retrieval from web sources\n\nIn-line attributions and links to original content\n\nPublisher Controls & Content Management\n\nOpenAI is also introducing tools for publishers to manage how their content appears in SearchGPT, giving them more control over their presence in AI-powered search results.\n\nKey points about the publisher controls include:\n\nSeparate from AI training: OpenAI emphasizes that SearchGPT is distinct from the training of their generative AI models. Sites can appear in search results even if they opt out of AI training data. Content management options: Publishers can influence how their content is displayed and used within SearchGPT. Feedback mechanism: OpenAI has provided an email (publishers-feedback@openai.com) for publishers to share their thoughts and concerns. Performance insights: The company plans to share information with publishers about their content’s performance within the AI search ecosystem.\n\nThese tools are OpenAI’s response to ongoing debates about AI’s use of web content and concerns over intellectual property rights.\n\nPublisher Partnerships & Reactions\n\nOpenAI reports collaborating with several publishers during the development of SearchGPT.\n\nNicholas Thompson, CEO of The Atlantic, provided a statement supporting the initiative, emphasizing the importance of valuing and protecting journalism in AI search development.\n\nRobert Thomson, News Corp’s chief executive, also commented on the project, stressing the need for a symbiotic relationship between technology and content and the importance of protecting content provenance.\n\nLimited Availability & Future Plans\n\nCurrently, SearchGPT is available to a restricted group of users and publishers.\n\nOpenAI describes it as a temporary prototype, indicating plans to integrate features into their existing ChatGPT product eventually.\n\nWhy This Matters\n\nThe introduction of SearchGPT represents a potential shakeup to the search engine market.\n\nThis development could have far-reaching implications for digital marketing, content creation, and user behavior on the internet.\n\nPotential effects include:\n\nChanges in content distribution and discovery mechanisms\n\nNew considerations for search engine optimization strategies\n\nEvolving relationships between AI companies and content creators\n\nRemember, this is still a prototype, and we have yet to see its capabilities.\n\nThere’s a waitlist available for those trying to get their hands on it early.\n\nWhat This Means For You\n\nAI-powered search might offer users more direct access to information. However, the accuracy and comprehensiveness of results may depend on publisher participation and content management choices.\n\nFor content creators and publishers, these new tools provide opportunities to have more say in how their work is used in AI search contexts.\n\nWhile it may increase content visibility and engagement, it also requires adapting to new formats and strategies to ensure content is AI-friendly and easily discoverable.\n\nAs SearchGPT moves from prototype to integration with ChatGPT, it will be vital to stay informed about these developments and adapt your strategies.\n\nThe future of search is evolving, and AI is at the forefront of this transformation."
    }
]